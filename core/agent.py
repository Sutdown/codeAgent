from __future__ import annotations
import json
from dataclasses import dataclass
from typing import Any, Callable, Dict, List, Optional

from clients import BaseClient
from core.planner import TaskPlanner, PlanStep
from memory import ContextCompressor
from prompts import build_code_agent_prompt
from tools import Tool


@dataclass
class Step:
    """è¡¨ç¤ºæ™ºèƒ½ä½“çš„ä¸€ä¸ªæ¨ç†æ­¥éª¤ã€‚"""

    thought: str                 # æ™ºèƒ½ä½“çš„æ€è€ƒè¿‡ç¨‹
    action: str                  # è¦æ‰§è¡Œçš„åŠ¨ä½œ/å·¥å…·åç§°
    action_input: Any            # åŠ¨ä½œçš„è¾“å…¥å‚æ•°
    observation: str             # æ‰§è¡ŒåŠ¨ä½œåçš„è§‚å¯Ÿç»“æœ
    raw: str = ""                # åŸå§‹å“åº”å†…å®¹

class ReActAgent:
    """ReActä»£ç†ï¼ŒåŸºäºLLMå’Œå·¥å…·è¿›è¡Œæ¨ç†ã€‚"""
    def __init__(
            self,
            client: BaseClient,
            tools : List[Tool],
            *,
            max_steps: int = 200,
            temperature: float = 0.0,
            system_prompt: Optional[str] = None,
            step_callback: Optional[Callable[[int, Step], None]] = None,  # æ­¥éª¤å›è°ƒå‡½æ•°
            enable_planning: bool = True,
            enable_compression: bool = True,
    ) -> None:
        if not tools:
            raise ValueError("å¿…é¡»ä¸º ReactAgent æä¾›è‡³å°‘ä¸€ä¸ªå·¥å…·ã€‚")

        self.client = client                             # ä¸å¤§æ¨¡å‹é€šè¯çš„å®¢æˆ·ç«¯
        self.tools = {tool.name: tool for tool in tools} # å¯ç”¨å·¥å…·çš„æ˜ å°„
        self.tools_list = tools                          # å·¥å…·åˆ—è¡¨ï¼Œç”¨äºè§„åˆ’å™¨åˆå§‹åŒ–

        self.max_steps = max_steps
        self.temperature = temperature
        self.system_prompt = system_prompt or build_code_agent_prompt(tools)

        self.step_callback = step_callback                   # æ­¥éª¤æ‰§è¡Œå›è°ƒå‡½æ•°
        self.conversation_history: List[Dict[str, str]] = [] # å¤šè½®å¯¹è¯å†å²è®°å½•

        # è§„åˆ’å™¨
        self.enable_planning = enable_planning
        self.planner = TaskPlanner(client, tools) if enable_planning else None

        # ä¸Šä¸‹æ–‡å‹ç¼©å™¨ï¼ˆæ¯ 5 è½®å¯¹è¯å‹ç¼©ä¸€æ¬¡ï¼‰
        self.enable_compression = enable_compression
        self.compressor = ContextCompressor(client, compress_every=5, keep_recent=3) if enable_compression else None

    def run(self, task: str, *, max_steps: Optional[int] = None) -> Dict[str, Any]:
        """æ‰§è¡ŒæŒ‡å®šä»»åŠ¡
        è¯¥æ–¹æ³•å®ç°äº†å®Œæ•´çš„ReActå¾ªç¯ï¼ŒåŒ…æ‹¬ä»»åŠ¡è§„åˆ’ã€æ¨ç†ã€è¡ŒåŠ¨å’Œè§‚å¯Ÿç­‰é˜¶æ®µã€‚å®ƒæ”¯æŒä¸Šä¸‹æ–‡å‹ç¼©ä»¥
        æ§åˆ¶tokenæ¶ˆè€—ï¼Œå¹¶æä¾›å›è°ƒæœºåˆ¶ç”¨äºç›‘æ§æ‰§è¡Œè¿‡ç¨‹ã€‚
        """
        if not isinstance(task, str) or not task.strip():
            raise ValueError("ä»»åŠ¡å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²ã€‚")

        steps: List[Step] = []
        limit = max_steps or self.max_steps  # è·å–æœ€å¤§æ­¥éª¤æ•°

        # é€šè¿‡è§„åˆ’å™¨ç”Ÿæˆè®¡åˆ’
        plan: List[PlanStep] = []
        if self.enable_planning and self.planner:
            try:
                plan = self.planner.plan(task)
                if plan:
                    plan_text = self.planner.get_process()
                    print(f"\nğŸ“‹ ç”Ÿæˆçš„æ‰§è¡Œè®¡åˆ’ï¼š\n{plan_text}")
            except Exception as e:
                print(f"è­¦å‘Šï¼šè®¡åˆ’ç”Ÿæˆå¤±è´¥ - {e}")

        # æ·»åŠ æ–°ä»»åŠ¡åˆ°å¯¹è¯å†å²
        task_prompt : str = self._build_user_prompt(task, steps, plan)
        self.conversation_history.append({"role": "user", "content": task_prompt})

        for step_num in range(1, limit + 1):
            messages_to_send = [{"role": "system", "content": self.system_prompt}] + self.conversation_history
            # å‹ç¼©ä¸Šä¸‹æ–‡
            if self.enable_compression and self.compressor:
                if self.compressor.should_compress(self.conversation_history):
                    print(f"\nğŸ—œï¸ å‹ç¼©å¯¹è¯å†å²ä»¥èŠ‚çœ token...")
                    compressed_history = self.compressor.compress(self.conversation_history)
                    messages_to_send = [{"role": "system", "content": self.system_prompt}] + compressed_history

                    # æ˜¾ç¤ºå‹ç¼©ç»Ÿè®¡
                    stats = self.compressor.get_compression_stats(
                        self.conversation_history, compressed_history
                    )
                    print(
                        f"   å‹ç¼©ç‡ï¼š{stats['compression_ratio']:.1%}ï¼Œ"
                        f"èŠ‚çœ {stats['saved_messages']} æ¡æ¶ˆæ¯"
                    )

            # è·å– AI å“åº”
            raw = self.client.chat(messages_to_send, temperature=self.temperature)
            self.conversation_history.append({"role": "assistant", "content": raw})

            # å°† AI å“åº”æ·»åŠ åˆ°å†å²è®°å½•
            self.conversation_history.append({"role": "assistant", "content": raw})
            try:
                parsed = self._parse_agent_response(raw)
            except ValueError as exc:
                observation = f"è§£ææ™ºèƒ½ä½“å“åº”å¤±è´¥ï¼š{exc}"
                step = Step(
                    thought="",
                    action="error",
                    action_input={},
                    observation=observation,
                    raw=raw,
                )
                steps.append(step)

                # å°†é”™è¯¯è§‚å¯Ÿæ·»åŠ åˆ°å†å²è®°å½•
                self.conversation_history.append({"role": "user", "content": f"è§‚å¯Ÿï¼š{observation}"})

                if self.step_callback:
                    self.step_callback(step_num, step)
                continue

            # è·å–åŠ¨ä½œã€thought å’Œè¾“å…¥
            action = parsed.get("action", "").strip()
            thought = parsed.get("thought", "").strip()
            action_input = parsed.get("action_input")

            # æ£€æŸ¥æ˜¯å¦å®Œæˆ
            if action == "finish":
                final = self._format_final_answer(action_input)
                step = Step(
                    thought=thought,
                    action=action,
                    action_input=action_input,
                    observation="<finished>",
                    raw=raw,
                )
                steps.append(step)

                # æ·»åŠ å®Œæˆæ ‡è®°åˆ°å†å²è®°å½•
                self.conversation_history.append({"role": "user", "content": f"ä»»åŠ¡å®Œæˆï¼š{final}"})

                # å¤„ç†ä»»åŠ¡ç»“æŸæ—¶çš„å›è°ƒé€šçŸ¥å’Œç»“æœå°è£…
                if self.step_callback:
                    self.step_callback(step_num, step)
                return {"final_answer": final, "steps": [step.__dict__ for step in steps]}

            # æ£€æŸ¥å·¥å…·
            tool = self.tools.get(action)
            if tool is None:
                observation = f"æœªçŸ¥å·¥å…· '{action}'ã€‚"
                step = Step(
                    thought=thought,
                    action=action,
                    action_input=action_input,
                    observation=observation,
                    raw=raw,
                )
                steps.append(step)

                # å°†è§‚å¯Ÿç»“æœæ·»åŠ åˆ°å†å²è®°å½•
                self.conversation_history.append({"role": "user", "content": f"è§‚å¯Ÿï¼š{observation}"})

                if self.step_callback:
                    self.step_callback(step_num, step)
                continue

            # task_complete å·¥å…·å¯ä»¥æ¥å—å­—ç¬¦ä¸²æˆ–ç©ºå‚æ•°
            if action == "task_complete":
                if action_input is None:
                    action_input = {}
                elif isinstance(action_input, str):
                    action_input = {"message": action_input}
                elif not isinstance(action_input, dict):
                    action_input = {}

                try:
                    observation = tool.execute(action_input)
                except Exception as exc:  # noqa: BLE001 - å°†å·¥å…·é”™è¯¯ä¼ é€’ç»™ LLM
                    observation = f"å·¥å…·æ‰§è¡Œå¤±è´¥ï¼š{exc}"
            elif action_input is None:
                observation = "å·¥å…·å‚æ•°ç¼ºå¤±ï¼ˆaction_input ä¸º nullï¼‰ã€‚"
            elif not isinstance(action_input, dict):
                observation = "å·¥å…·å‚æ•°å¿…é¡»æ˜¯ JSON å¯¹è±¡ã€‚"
            else:
                try:
                    observation = tool.execute(action_input)
                except Exception as exc:  # noqa: BLE001 - å°†å·¥å…·é”™è¯¯ä¼ é€’ç»™ LLM
                    observation = f"å·¥å…·æ‰§è¡Œå¤±è´¥ï¼š{exc}"

            # å·¥å…·é‡‡å–è¡ŒåŠ¨çš„æ‰§è¡Œç»“æœ
            step = Step(
                thought=thought,
                action=action,
                action_input=action_input,
                observation=observation,
                raw=raw,
            )
            steps.append(step)

            # æ›´æ–°è®¡åˆ’è¿›åº¦
            if plan and self.planner:
                # æŸ¥æ‰¾å½“å‰æ­¥éª¤å¯¹åº”çš„è®¡åˆ’æ­¥éª¤
                for plan_step in plan:
                    if plan_step.action == action and not plan_step.completed:
                        self.planner.mark_completed(plan_step.step_number, observation)
                        break

            # å°†å·¥å…·æ‰§è¡Œç»“æœæ·»åŠ åˆ°å†å²è®°å½•
            tool_info = f"æ‰§è¡Œå·¥å…· {action}ï¼Œè¾“å…¥ï¼š{json.dumps(action_input, ensure_ascii=False)}\nè§‚å¯Ÿï¼š{observation}"
            self.conversation_history.append({"role": "user", "content": tool_info})

            # è°ƒç”¨å›è°ƒå‡½æ•°å®æ—¶è¾“å‡ºæ­¥éª¤
            if self.step_callback:
                self.step_callback(step_num, step)

            # æ£€æŸ¥æ˜¯å¦è°ƒç”¨äº† task_complete å·¥å…·
            if action == "task_complete" and not observation.startswith("å·¥å…·æ‰§è¡Œå¤±è´¥"):
                return {
                    "final_answer": observation,
                    "steps": [step.__dict__ for step in steps],
                }

        return {
            "final_answer": "è¾¾åˆ°æ­¥éª¤é™åˆ¶ä½†æœªå®Œæˆã€‚",
            "steps": [step.__dict__ for step in steps],
        }

    def _build_user_prompt(self, task: str, steps: List[Step], plan: List[PlanStep] = None) -> str:
        """æ„å»ºç”¨æˆ·æç¤ºè¯"""
        lines : List[str] = [f"ä»»åŠ¡ï¼š{task.strip()}"]
        # å¦‚æœæœ‰è®¡åˆ’ï¼Œæ·»åŠ åˆ°æç¤ºä¸­
        if plan:
            lines.append("\næ‰§è¡Œè®¡åˆ’ï¼š")
            for plan_step in plan:
                status = "âœ“" if plan_step.completed else "â—‹"
                lines.append(f"{status} æ­¥éª¤ {plan_step.step_number}: {plan_step.action} - {plan_step.reason}")

        if steps:
            lines.append("\nä¹‹å‰çš„æ­¥éª¤ï¼š")
            for index, step in enumerate(steps, start=1):
                lines.append(f"æ­¥éª¤ {index} æ€è€ƒï¼š{step.thought}")
                lines.append(f"æ­¥éª¤ {index} åŠ¨ä½œï¼š{step.action}")
                lines.append(f"æ­¥éª¤ {index} è¾“å…¥ï¼š{json.dumps(step.action_input, ensure_ascii=False)}")
                lines.append(f"æ­¥éª¤ {index} è§‚å¯Ÿï¼š{step.observation}")
        lines.append(
            "\nç”¨ JSON å¯¹è±¡å›åº”ï¼š{\"thought\": string, \"action\": string, \"action_input\": object|string}ã€‚"
        )
        return "\n".join(lines)

    def _parse_agent_response(self, raw: str) -> Dict[str, Any]:
        """è§£ææ™ºèƒ½ä½“å“åº”"""
        candidate = raw.strip()
        if not candidate:
            raise ValueError("æ— æ•ˆçš„å“åº”")
        try:
            parsed = json.loads(candidate)
        except json.JSONDecodeError:
            start = candidate.find("{")
            end = candidate.rfind("}")
            if start == -1 or end == -1 or end <= start:
                raise ValueError("å“åº”ä¸æ˜¯æœ‰æ•ˆçš„ JSONã€‚")
            snippet = candidate[start: end + 1]
            parsed = json.loads(snippet)
        if not isinstance(parsed, dict):
            raise ValueError("æ™ºèƒ½ä½“å“åº”çš„ JSON å¿…é¡»æ˜¯å¯¹è±¡ã€‚")
        return parsed

    def reset_conversation(self) -> None:
        self.conversation_history = []

    def get_conversation_history(self) -> List[Dict[str, str]]:
        return self.conversation_history.copy()

    @staticmethod
    def _format_final_answer(action_input: Any) -> str:
        if isinstance(action_input, str):
            return action_input
        if isinstance(action_input, dict) and "answer" in action_input:
            value = action_input["answer"]
            if isinstance(value, str):
                return value
        return json.dumps(action_input, ensure_ascii=False)


